# YLLSOD
# Dataset Analysis
The dataset consists of a total of 3263 pairs of images, all with a resolution of 384Ã—384. 
As shown in the following figure, the overall distribution of the dataset is depicted by the dual-layered pie chart on the left side. 
The inner layer of the ring represents the proportions of each sub-dataset in the total dataset. 
Specifically, RGBD-385, RGBT-621, RGB-252, VDT-766, VI-789, and LL-450 account for 24%, 14%, 12%, 19%, 8%, and 23% of the total data, respectively. 
The outer layer of the ring represents the proportions of data used for training and testing within each sub-dataset in relation to the total dataset. 
On the right side of the following figure, data samples from each sub-dataset are showcased.
The first and third rows depict low-light RGB images, while the second and fourth rows display the corresponding ground truth annotations.
![data](https://github.com/ynn1030/YLLSOD/assets/151114415/d2567942-68a4-4e8a-b8d8-ef7990142668)
# Category Analysis
The samples are categorized based on the size of salient objects into BSO (big salient object), SSO (small salient object), and MSO (multiple salient objects). The dataset also includes images captured under extreme darkness (ED) conditions and images with uneven illumination (UI). Additionally, the dataset covers both indoor scenes (IS) and outdoor scenes (OS). This dataset serves as a fundamental resource for evaluating the performance of SOD methods in challenging low-light environments.

Paper: Degradation-removed multiscale fusion for low-light salient object detection. Nana Yu, Jie Wang, Hong Shi, Zihao Zhang, and Yahong Han. Pattern Recognition

The dataset is available: https://pan.baidu.com/s/1zES28jb_EIH2yZwcMBcfDw     1y3n 
